% !TEX root = MutationTestingSurvey.tex

\section{Data-driven Mutation Operators}
\label{sec:data_operators}

As mentioned in Section~\ref{sec:dataProcess}, the software engineering literature does not include any study on data-driven mutation testing but only testing approaches based on the injection of data faults.
For this reason, 
in this section we provide an overview of the fault injection techniques that have originally been developed to support software testing and can be used in the context of data-driven mutation testing. 
More precisely, we focus on the techniques for the modification of data that are presented in software testing research papers.
We refer to these techniques as \emph{data-driven mutation operators}.

Table~\ref{table:dataOperators} provides an overview of the data-driven mutation operators that can be applied to the case of space software and embedded systems. 
We selected the set of data-driven mutation operators in Table~\ref{table:dataOperators} based on the different type of faults commonly affecting space and embedded systems. 
Each operator aims to create data faults that might be observed in real systems either because of hardware errors or software errors.

In Table~\ref{table:dataOperators}, column \emph{Name} provides the name of the specific operator described, column Model-based indicates if the operator requires a model of the structure of the data to be mutated, 
 column \emph{Type of fault} indicates the type of faults each operator aims to simulate,
 column \emph{Definition} provides a brief description of the mutation operator, column \emph{Target} indicates the type of data targeted by the approach,
 column \emph{Reference} provides a reference to a research paper or tool describing the operator more in detail.
 
%Fabrizio: "First" and "Then" read like a story, which is not good in a Tech Report
Concerning the type of faults considered, we focus both on hardware and software errors.
For hardware errors, we include the categories \emph{CPU Faults}, \emph{Memory Faults}, and \emph{Signal Faults}. 
For software errors, we include the category of \emph{Data Processing Faults}.
Category \emph{Communication Faults} simulates problems that can be caused either by software or hardware errors.

In the following, we provide a brief overview of the operators generating each type of fault:
\begin{itemize}
	%Note: always put a comma at the end of a list before "or" "and"
	\item Category \emph{CPU Faults} includes operators that perform mutations in the contents of an individual bit, byte, or word in a CPU register. The mutations in this category can target saved, floating-point, program-counter, global and stack-pointer register locations. 
	\item Category \emph{Memory Faults} includes operators that perform mutations in the contents of an individual bit, byte, or word in a memory register. The mutations in this category can target stack, heap, global-data and user-defined memory locations.
	\item Category \emph{Communication Faults} includes operators that simulate packet corruption faults. The mutations in this category can target channels between components, single messages, and the addresses of the messages to be exchanged.
	\item Category \emph{Data Processing Faults} includes techniques that mutate the data being processed by the system. Some of these techniques are white-box, they process the source code of the application to generate inputs more efficiently. Other techniques require a model of the data to be mutated. The mutations in this category can target both the input and the output parameters of the interface of a software component.
\end{itemize}

\input{tables/table_data_operators}

Among all the data mutation operators reported in Table~\ref{table:dataOperators}, the ones targeting \emph{Data Processing Faults} are more powerful since they concern the modification of complex data structures. %Oscar: not sure that "overviewed" is spelled right %They are briefly overviewed in the following.
\CHANGED{We provide an overview in the following.}

\emph{AFL} introduces instrumentation-guided fuzzers, it uses a form of edge coverage to pick up subtle changes to program control-flow~\cite{gutmann2016fuzzing}. This way, it ensures to generate inputs that exercise all the different code paths.
Although AFL tackles the redundant mutants problem (i.e., does not generate different test inputs for the same execution path), it may produce equivalent mutants.
%Fabrizio: you had this definition of equivalent: "(i.e., correct fuzzed data, but semantically meaningless)." it is difficult to understand

\emph{Parser-Directed Fuzzing} aims at producing valid inputs for input parsers~\cite{mathis2019parser}. The challenge is to cover all the lexical and syntactical features of a certain language. The approach systematically produces inputs for the parser and tracks all the comparisons made; after every rejection, it satisfies the comparisons leading to rejections, effectively covering the input space. 
Evaluated on five subjects, from CSV files to JavaScript, the \emph{pFuzzer} prototype covers more tokens than both lexical-based (AFL) and constraint-based approaches (KLEE).
\CHANGED{Even though, \emph{pFuzzer} tackles the problem of redundant mutant by well covering the space of possible inputs, it may produce equivalent mutants.}
%Fabrizio: I cannot understand the following sentences
%Although it tackles the problem of redundant mutants by well covering the space of possible inputs, it does not tackle the redundant mutant problem.
%Cannot handle semantic restrictions imposed by certain nontrivial input languages. The approach has difficulties to handle complex sequences recursion.

\emph{RIDDLE}~\cite{ghosh1998testing} adopts a grammar to describe the format of inputs; random and boundary values are generated for tokens representing input parameters.
One of its drawbacks is the cost of setting up a grammar to describe the space of program inputs.
%, also, it requires more knowledge about the target than purely random ones.

\emph{SAGE} adopts symbolic execution to systematically generate malformed inputs~\cite{godefroid2012sage}. SAGE performs fuzzing on file- and packet-parsing applications. 
The program is first executed with concrete inputs; in order to identify a set of constraints on inputs, then, one of the constraints in the set is negated, and new malformed inputs are generated to satisfy the new set of constraints. 
The main benefit of SAGE is that it forces the program to execute corner cases not covered by the initial inputs; for example, 
%Fabrizio: you wrote the following, which I could not understand please check if my sentence is correct
%(e.g., reached one-third of all bugs found by fuzz testing in Microsoft projects \cite{bounimova2013billions}).
%Oscar: yes, what you wrote is correct 
one-third of all the bugs found by means of fuzz testing are detected thanks to SAGE \cite{bounimova2013billions}.
Unfortunately the main limitation of SAGE and symbolic execution-based fuzzers is limited scalability, due to the high execution time required by symbolic execution.

%Fabrizio: not sure what the following is about, ignoring
%\emph{Testing of Fault-Tolerant and Real-Time Distributed Systems via Protocol Fault Injection \cite{dawson1996testing}}: The paper introduces a portable fault injection environment for testing implementations of distributed protocols.

%Fabrizio: we miss the pro/cons from the following
\emph{Model-Based Whitebox Fuzzing} targets program binaries that process structured inputs~\cite{pham2016model}. It efficiently generates valid inputs that exercise critical target locations. This is done through a directed path exploration technique that prunes from the search space those paths that are exercised by invalid, malformed inputs.
\CHANGED{Compared with a Model-Based Blackbox Fuzzer (MoBF) approach, the \emph{MoWF} prototype was able to expose all of 13 vulnerabilities on an empirical evaluation carried on nine subject programs, while the MoBF approach only detected 6 out of 13 vulnerabilities. The paper indirectly addresses the problem of redundant mutants by performing a systematic path exploration search covering critical locations in the source code (e.g., well covering the space of possible inputs).} 

%\emph{Generating complex and faulty test data through model-based mutation analysis (Research paper) \cite{di2015generating}}: 
\emph{Model-based data mutation} concerns the automated generation of invalid input data through the mutation of existing data based on a predefined set of mutation operators~\cite{di2015generating}.
The technique relies upon six generic mutation operators to automatically generate faulty data. The technique receives two inputs: field data and a data model, i.e., a UML class diagram annotated with stereotypes and OCL constraints. Stereotypes are used to tailor the behaviour of the generic mutation operators to the fault model that is assumed for the system under test and the environment in which it is deployed. 
OCL constraints are used to capture the characteristics of valid inputs and to indicate which error messages should be produced by the system in the presence of violations of input constraints.
The use of stereotypes and OCL constraints enable the approach to partially addresses the problem of equivalent mutants. Indeed stereotypes indicate which data fields to mutate, while OCL constraints indicates which violations should be reported by the SUT.

\emph{Search-based data mutation} relies on an evolutionary algorithm to perform model-based data mutation and optimize multiple objectives:  
cover all the classes of the data-model, cover all the possible faults of the fault model, cover all the clauses of the input/output constraints,
maximise code coverage~\cite{di2015evolutionary}.
The coverage of each objective is encoded by means of boolean arrays; this information is used to select a minimal set of inputs that maximize the coverage of the different objectives.
At every iteration, the evolutionary algorithm keeps only inputs that contribute to increase the coverage of at least one of the objectives (e.g., inputs that cover one instruction not covered by other inputs).
The paper indirectly addresses the problem of redundant mutants thanks to the inclusion of a coverage objective in the fitness; indeed only mutants that cover different portions of the code are kept, by definition these mutants are distinct because they trigger distinct software behaviours.

