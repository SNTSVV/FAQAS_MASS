% !TEX root = MutationTestingSurvey.tex
\clearpage
\subsection{Solutions to Improve Run-time Scalability}
\label{sec:opt:execution}

In the mutation testing process, the execution of mutants is the major source of \INDEX{scalability issues} (i.e., it requires a lot of time to be completed). Indeed, with $n$ mutants for a program under test and a test suite of $m$ test cases, $n \times m$ executions are required to apply mutation testing.

%Fabrizio: I am not sure which formatting we should use for ESA. Let's try to follow the SI System
This might make mutation testing infeasible. For example, a test suite that requires 10 hours to be executed against the software under test, would require 1\,000\,000 hours or 114 years be executed against 100\,000 mutants; for a large space system with 10\,000 lines of code, 100\,000 mutants can be easily generated  with 10 mutants generated for each line of code, on average.

To cope with the run-time cost of mutation testing, several solutions had been proposed in the literature, they are summarized in the following paragraphs.

\INDEX{Random mutation testing} consists of  randomly selecting a certain percentage of the generated mutants. So, instead of executing all the mutants only a reduced percentage is executed.

Zhang et al. \cite{zhang2010operator} demonstrated that a test suite that is capable of killing 50\% of the mutants results in killing more than 99\% of all mutants.

Gopinath et al \cite{gopinath2015hard} show that the mutation score obtained for a subset of the mutants is representative of the mutation score obtained by considering all the mutants. Best results were obtained by considering 1 000 mutants. The number of mutants to consider is independent of the total number of available mutants. With 1 000 mutants, the error in the prediction of the mutation score was 7\% with a probability of 95\%. 
In a similar fashion, Zhang et al. \cite{zhang2013operator} empirically demonstrated that with a 5\% of random selected mutants is sufficient for predicting the mutation score. \CHANGEDTWO{Also,
they show that sampling mutants uniformly across different program elements (i.e., to have a same percentage of mutants selected for every function/methods) leads to a more accurate mutation score prediction than randomly sampling mutants globally. It also fares better than uniformly distributing the sampled mutants across different mutation operators (i.e., to have a similar number of mutants for each mutation operator.}


\INDEX{Selective mutation testing} relies on the idea that certain type of mutants are more important than others and may result in more representative faults. In selective mutation only a subset of operators are applied to the source code application.
Offutt et al. \cite{offutt1996experimental}, then Andrews et al. \cite{andrews2005mutation}, and more recently Namin et al. \cite{siami2008sufficient} have worked on the \INDEX{sufficient set of operators}. This restricted set of operators produce equivalent mutation score as broader classes of operators. Initially, this set was composed by the \textit{ABS, AOR, LCR, ROR} and \textit{UOI} classes of operators, but in the more recent work from Namin et al. \cite{siami2008sufficient} they redefined this set through a statistical analysis which identified 28 operators as the new sufficient set. According to their results, by using this set, it is possible to reduce the number of mutants up to 93\%. 

\DONE{I cannot understand what is "effectiveness". Do you mean "ensuring a high fault detection rate", "leading to a mutation score that is close to the one obtained with more mutants", or what?}
%More recently, Gopinath et al. \cite{gopinath2016limits} demonstrated that the improvement of random over selective mutation does not exceed 13\%.
More recently, Gopinath et al.~\cite{gopinath2016limits} performed an empirical comparison between random and selective mutant selection strategies; based on the observed results they concluded that the maximum possible improvement in the effectiveness of selective over random mutation is 13\%, where effectiveness measures the ability of the strategy to lead to a mutation score that is close to the one obtained with more mutants.

Delamaro et al. \cite{delamaro2014designing,delamaro2014experimental} experimented with mutants that involve deletion operations (\INDEX{statements deletion}) and found that they form a cost-effective alternative to other operators and selective mutation strategies. Indeed, deletion operators produce significantly less equivalent mutants (8.5\% in comparison to the average of 11.9\% during experimentation). 
In \cite{delamaro2014experimental}, Delamaro et al. experimented with mutation operators that delete variables, operators, and constants. They show that a test suite that kills the mix of OODL (deletion of arithmetic and relational operators) and SSDL (deletion of statements) mutants kills a very high percentage of all mutants (97\% of mutation score).

Some other solutions rely on \INDEX{code coverage}. Mutants that belong to code locations that are not exercised by any test case should not be executed because there is no chance of being killed. Code coverage collected during the execution of the test suite against the original software can be used to determine if a code location is exercised; this approach has been implement by the Proteum tool \cite{delamaro1996proteum}.
Similarly, mutants that have been already killed by a test case should not be executed against other test cases.

Other solutions concern the \INDEX{prioritization of test cases}. Just et al. \cite{just2012using} and Zhang et al. \cite{zhang2013faster} proposed to sort test cases to kill mutants as early as possible, e.g., by executing first the test cases with a shorter runtime~\cite{just2012using}. 

%Papadakis and Malevris \cite{papadakis2011automatically} gave a step further in this research line, and proposed that a way to prioritise the  different mutants is by assessing in advance which of the mutants are actually modifying the variables that check the killing condition of the mutant, i.e., the final assertion of a test case, and prioritise them over mutants that do not modify variables related to the killing condition.
\DONE{Sorry, but I am not sure to get it. 
Do you mean the following:
"Papadakis and Malevris \cite{papadakis2011automatically} rely on data-flow analysis to determine if the \INDEX{killing conditions} for a mutant are satisfied (see Section~\ref{sec:testGen:CP}). Mutants that satisfy the killing conditions are executed before others."}
%Papadakis and Malevris \cite{papadakis2011automatically} rely on data-flow analysis to determine which mutants modify variables that reach the \INDEX{killing condition} of the mutant (i.e., the program execution path that lead the mutant to be killed). These mutants are prioritized over mutants that do not modify variables reaching a killing condition.

Papadakis and Malevris \cite{papadakis2011automatically} rely on data-flow analysis to determine if the \INDEX{killing conditions} for a mutant are satisfied (see Section~\ref{sec:testGen:CP}). Mutants that satisfy the killing conditions are executed before others.


The use of weak and firm mutation over strong mutation may speed up mutation testing as well.
Unlike strong mutation, 
%i.e., the mutant and the original program must show an observable difference (e.g., the result of an assertion), 
in \INDEX{weak mutation} \cite{ammann2016introduction}, the mutant is killed if the program state is modified immediately after the mutation; the advantage of weak mutation is that it does not require a complete execution to determine if the mutant has been killed. Similarly to weak mutation, in \INDEX{firm mutation} \cite{ammann2016introduction}, the assessment of the killing condition is placed in between weak and strong mutation; typically by checking if the result generated by a mutated function (e.g., the return value) differs from the result of the original function. The main drawback of both the two approaches is that they sacrifice test effectiveness; more precisely, they cannot ensure that the difference in the behaviour of the software is reflected in a test failure.

%Fabrizio: the following is a conclusion that makes sense to evaluate the two approaches in terms of test assessment effectivenes, however in this chapter we are discussing speed-up
%In a nutshell, weak mutation is considered less effective than firm mutation, and firm mutation is considered less effective than strong mutation.

Sometimes mutation operators introduce code changes that prevent the \INDEX{termination of test cases} (e.g., infinite loops), which requires the intervention of human operators and, consequently, a delay in the completion of the mutation testing process.
For this reason, several mutation tools rely on time thresholds to force the termination of test case executions. 
A simple solution, consists in forcing the termination of a test case (executed against a mutated program) when its execution time  takes more than three times the execution time required for the original program~\cite{papadakis2019mutation}.

King and Offutt \cite{king1991fortran} presented \INDEX{split-stream} execution, a technique that takes advantage of the fact that a program and its mutants share most of the execution parts. Instead of having one executable per mutant it could be possible to generate a modified version of the SUT that creates multiple processes (one for each mutant) only when the mutated code is reached \cite{tokumoto2016muvm}, thus saving time and resources. 

An orthogonal solution is to \EMPH{reduce and/or prioritise} the number of test cases that are executed during mutation testing.

For \INDEX{test case reduction}, the idea is to remove those test cases that are somehow redundant (e.g., test cases that when removed from the test suites do not change the mutation score).
Usaola et al. \cite{usaola2012reduction} proposed a greedy algorithm that iteratively selects  the test cases that kill most of the mutants that were not killed by the previously selected test cases. 
%\DONE{No change to do here. However please keep them in mind for the current work.}
Shi et al. \cite{shi2014balancing} assessed the effects of reducing the size of test suites with an experiment on 18 projects with a total of 261\,235 test cases. Their results show that \EMPH{it is possible to maintain constant the mutation score and reduce test suite size without loss in the \INDEX{fault detection rate}}. 
On the same line, Zhang et al. \cite{zhang2013faster} suggest to define a subset of tests of the original test suite and to run the mutants against the subset, their assumption is that if the mutants cannot be killed by the subset also the original test suite will not be able to kill the mutants.

Concerning \INDEX{test case prioritization}, the idea is to sort the test cases in order to kill the mutants as early as possible. For instance, Just et al. \cite{just2012using} proposed to execute first those test cases with shorter runtime for time saving.

\DONE{Why do we have both context and nighbourhood? Are the same thing? Yep, the same, left only neighborhood}

Zhang et al. \cite{zhang2013faster} proposed two approaches for sorting the test cases; the first is based on the code coverage, it prioritizes test cases that execute the mutated statement more times because they have a higher probability to kill the mutant, 
the second approach prioritizes test cases that kill mutants whose mutated statement is close to the mutated statement of the mutant under test. Two mutants are considered close if their mutation point resides within the same or neighborhood. The neighborhood is defined at multiple levels (i.e., same statement, same method, or same class).
\DONE{Do you mean the following "In their empirical evaluation, Zhang et al. observed that the integration of both the two approaches (the latter with a class neighborhood) lead to a reduction of the number of test case executions of up to 44\%." ?}
%In their empirical evaluation, Zhang et al. observed an improvement up to 44\% less test case executions when applying together the two prioritization approaches on a class mutant neighborhood. 
In their empirical evaluation, Zhang et al. observed that the integration of both the two approaches (the latter with a class neighborhood) lead to a reduction of the number of test case executions of up to 44\%.

% (i.e., a test case that killed more mutants that are close to the mutant being tested has a higher likelihood to kill the current mutant).  


