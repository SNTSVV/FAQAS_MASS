% !TEX root = MutationTestingSurvey.tex
\clearpage
\section{Building Blocks of the Automated Test Suites Augmentation Process}
\label{sec:testGeneration}

This section describe the approaches that can be adopted to automatically generate test cases that kill mutants.
%Fabrizio:
To kill a mutant we need test cases that reach the mutation point (i.e., execute the mutated code), cause 
corruptions
%changes, or corruptions, 
in the program state right after the mutated code in comparison to the non-mutated version of the program, 
and manifest these corruptions into the program output 
%Fabrizio: an assertion is not an output
(e.g., by producing an erroneous value in a state variable verified by a test assertion) 
thus leading to a software failure \cite{papadakis2019mutation}, these conditions are also known as the killing conditions of a mutant.

In the literature, there exist two groups of approaches for 
%driving automated test generation processes aimed to kill mutants, based on the above mentioned conditions. 
generating test cases that kill mutants:
%Fabrizio: "symbolic procedures" is really the right terminology?
%Oscar: another term might be "Constraint-based"
%anywa, below symbolic execution is just part of the solutions adopted so we need a broader term
%The first group consists of techniques based on symbolic execution; the second group relies on search-based test generation techniques.
approaches based on constraint-programming, and approaches based on evolutionary computation.

%\subsection{Symbolic Test Generation Procedures}
\subsection{Test Generation based on Constraint Programming}

Techniques based on constraint programming use some form of automated reasoning (e.g., Propositional Satisfiability or Constraint Solving~\cite{SATandCPsurvey:2006}) to derive data that satisfy all the conditions necessary to kill a mutant~\cite{offutt1997automatically}.

One possibility consists of generating constraints that capture the three killing conditions of a mutant: reachability (i.e, the test case should execute the mutated statement), necessity (i.e., the test case should cause an incorrect intermediate state if it reaches the mutated statement), and sufficiency (i.e., the final state of the mutated program should differ from that of the original program)~\cite{offutt1997automatically}. Existing approaches, differ for the strategy adopted to automatically generate these constraints from the program under test.
Offutt et al. \cite{offutt1997automatically}, for example automatically derive such constraints from the program by extracting the predicate expressions on the program's control flow graph. Then, such constraints are encoded to form a constraint system, in their approach, they propose three strategies for identifying infeasible constraint systems, the contradictions to such systems are the new test cases for the program under analysis.

Holling et al. \cite{holling2016nequivack} proposed to use a symbolic execution approach to identify new test cases, the idea is to execute symbolically both the original and the mutated function, and then to check if their return values are equivalent or not. 
%F: I'm expecting a sentence as "Values are considered equivalent when ... "

Values are considered equivalent when both functions executed symbolically return the same output. Symbolic execution determines what inputs cause each part of a function to execute. To symbolically execute a function is necessary to change the original inputs, or concrete values, by symbolic ones. The symbolic values represent a set of possible concrete values that lead to a certain program path (i.e., path condition). To generate test cases, the path conditions produced by symbolic execution are processed by a SMT-solver, which returns the concrete values for that specific path condition. 
So, if both the mutated and the original function return the same outputs, means that there are not concrete values making the mutated function to produce a different output.

Each non-equivalent value proves that a new input that makes the original and the mutated function generate different results, has been found. 

To automate the generation of inputs, Holling et al. \cite{holling2016nequivack} rely on KLEE \cite{cadar2008klee}, a symbolic execution framework for programs written in C/C++.

We introduce an example of Holling's approach in Listing \ref{function}. The top part of Listing \ref{function} shows the function \texttt{isPositive}, which checks if an integer number is positive or not. The bottom part of Listing \ref{function} presents the mutated version of \texttt{isPositive}, where the relational operator $\geq$ has been replaced by the operator $>$.
To automate the generation of inputs using KLEE, all the parameters need to be treated as symbolic values.
%F: "the \texttt{isPositive} parameter \texttt{num}" it's impossible to understand what is the parameter and who owns the parameter
%In Holling's approach, first, the \texttt{isPositive} parameter \texttt{num} needs to be treated as symbolic value, which is done by the function \texttt{make\_symbolic} (see Listing \ref{example}) which converts concrete variables to symbolic by considering its memory address and size. 
This is achieved by function \texttt{make\_symbolic} (see Listing \ref{example}) which converts concrete variables to symbolic by considering its memory address and size. 
%F: please fix
In Listing \ref{example}, the parameter \texttt{numSymbolic} is made symbolic in Line 3. Then, the original and mutated functions are called using the symbolic arguments in Lines 5 and 6.
%Finally, the \texttt{assert} function of line 8 verifies if the integer return values of both functions are equal or not.
Finally, we need to introduce an assertion that verifies that the output of the two functions are different. 

In Listing \ref{example}, this is achieved by verifying that return values are different (see Line 8). 
This is done because symbolic execution approaches aim to identify inputs that falsify the assertions in the program. 
An input that falsifies such an equality is thus capable of identifying inputs that lead to different output falsifying the assertion.

%In the concrete, if we consider the implementation of \texttt{isPositive} and \texttt{MUT\_isPositive}, 
In the example of Listing \ref{example}, KLEE will indicate that the return values differ when \texttt{num} is equal to zero.
A new test case exercising function \texttt{isPositive} with \texttt{num=0} should thus be added to the test suite in order to kill the mutant.

\input{listings/holling_approach}

Similarly to Holling's approach, Riener et al. \cite{riener2011test} proposed to use bounded model checking techniques to search for these counter examples.
In their bounded model checking approach, the original program and the mutant are unrolled with respect to a certain maximum bound. Then, both unrolled programs are encoded into a logic formula over the same input variables. To ensure that the mutation affects the output of the mutant, a propagation condition is encoded and added to the previous logic formula, the condition asserts that there exist at least one pair of different outputs under the assumption of equal inputs. In the last step, the formula is handled by a SMT-solver, if the solver finds a satisfying assignment, the inputs of the formula are translated into a new test case for the current program under analysis.

%F: you should explain what is bounded-model checking. If Riener do not provide background you can check my ISSTA'14 paper (Verification-Aided Regression Testing), there is a background section (2) on bounded model checking that starts with "The idea in BMC is to represent ..."

Compared to symbolic execution, one advantage of bounded model checking is that it does not require to process all the functions.

To reduce the time required by the symbolic execution process, which needs to be performed against all the mutants of the software, Papadakis et al. \cite{papadakis2011automatically, papadakis2010towards} propose to combine symbolic execution techniques and mutant schemata to automatically generate test cases targeting the killing conditions induced by the different mutants embedded into the same executable. The approach targets weak mutation testing and may not generalize to firm mutation testing. Indeed, ensuring the sufficiency property (i.e., verify that changes are propagated to outputs) for multiple mutants might lead to scalability issues not addressed by the proposed approach.

\subsection{Test Generation based on Evolutionary Computation}

Test generation approaches based on evolutionary computation typically rely on population-based meta-heuristic optimization algorithms~\cite{harman2011strong}. 
They search for program inputs that could kill mutants under the guidance of a fitness function~\cite{harman2011strong}. 

The main research problem of these methods is the definition of fitness functions that capture the killing conditions of a mutant, and that identifies test inputs that satisfies those conditions.

The fitness function captures the killing conditions of a mutant. For instance, Ayari et al. \cite{ayari2007automatic} proposed to use an evolutionary approach based on ant colony optimization (ACO) for automatic test input data generation on mutation testing. The ACO is an optimization algorithm inspired by the behavior of real ants, it is based on the ants ability to find the shortest path between their nest and the food source. In the study by Ayari et al. \cite{ayari2007automatic}, the approach takes an existing test case and produces a new test case by slightly modifying its inputs. 
%F: you have to provide more details what does it mean "close"?
The fitness function measures the distance between the mutated statement, and the statement reached by the new test case (e.g., the reachability condition). Particularly, the distance is defined as the number of basic blocks existing between the two statements in the program's control flow graph.

Instead, Papadakis et al. \cite{papadakis2011automatically} rely on fitness functions that capture the distance between mutated statement and the statement covering the branches of the different mutations (e.g., the necessity condition).

Fraser and Arcuri \cite{fraser2015achieving} propose to use distinct distance metrics tailored to the specific operator used to generate the mutants.
%F: we need more examples for multiple operators. Also, you should clarify why distinct metrics are needed
The necessity killing condition relies on changes in the program state, and in some cases, the mutation operators change the program state, and in other cases the program state remains unchanged. Because of this, distinct metrics for measuring distance for each operators needs to be defined.
For example if the \textit{deletion operator} changes the program state (i.e., values on the stack are different at the mutation point) the distance is 0, otherwise the given value is 1. 
The \textit{insert unary operator} adds or subtracts 1 to a numerical value. The mutants produced by this operator will always affect the program state, so the distance is 0.
The \textit{replace variable operator} replaces a specific variable with all other variables of the same type in the program scope. In this case, the distance will be 0 if the values of the variables being exchanged are different, otherwise it is 1.

\endinput

\subsubsection{Symbolic execution test generation} % (fold)

\begin{itemize}

	\item Dynamic symbolic execution approaches: embed the mutant killing conditions within the executable program and guide test generation towards these conditions.

	\item Papadakis et al. \cite{papadakis2011automatically, papadakis2010towards}:
	Embed mutant infection conditions (cause a corruption to the program state) within the schematic functions that are produced by mutant schemata. Basically, we have all mutants encoded in a single executable with their killing conditions. Then, using dynamic symbolic execution we can directly produce test cases that targets those infection conditions.
\end{itemize}


